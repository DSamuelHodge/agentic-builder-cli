# LlmChat Function
# Generated by restack-gen on 2025-11-13

from restack_ai import function, log
from typing import List, Optional
from pydantic import BaseModel

class LlmChatInput(BaseModel):
    messages: List[dict]
    model: str = "gpt-4o-mini"
    temperature: float = 0.2

@function.defn()
async def llm_chat_function(input_data: dict) -> dict:
    """LlmChat function for testapp."""
    log.info("LlmChat function called", input=input_data)

    # Function logic here
    result = {
        "message": "Hello from llm_chat_function",
        "input": input_data,
        "function": "LlmChat"
    }

    log.info("LlmChat function completed", result=result)
    return result


if __name__ == "__main__":
    # For local testing
    import asyncio

    async def main():
        result = await llm_chat_function({"test": True})
        print(f"Function result: {result}")

    asyncio.run(main())